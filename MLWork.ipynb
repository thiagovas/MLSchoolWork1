{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Prático 1\n",
    "## Redes Neurais + Backpropagation\n",
    "\n",
    "Neste trabalho, implemento uma rede neural com três camadas.\n",
    "Aqui, uso algumas bibliotecas como pandas, numpy e keras.\n",
    "Todos os experimentos foram executados usando TensorFlow como backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', header=None, sep=',')\n",
    "\n",
    "Y = data[data.columns[0]]\n",
    "X = data[data.columns[1:]]\n",
    "\n",
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use Keras+scikit_learn it's necessary to define functions to build the models, hence that's what I'm going to do now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Model():\n",
    "    def __init__(self, plr=0.5, phl=25):\n",
    "        self.lr_ = plr\n",
    "        self.hl_ = phl\n",
    "        \n",
    "    \n",
    "    def __call__(self):\n",
    "        # Building model with keras\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hl_, input_dim=784, activation='sigmoid'))\n",
    "        model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "        sgd = optimizers.SGD(lr=self.lr_, decay=0.0, momentum=0.0, nesterov=False)\n",
    "\n",
    "        # Compiling the model...\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:<br/>\n",
    "O documento a ser entregue deverá apresentar o resultado de seus experimentos. Ou seja, deverá apresentar discussão da variação do número de unidades na camada oculta para cada um dos três algoritmos de cálculo de gradiente. Você deverá apresentar gráficos mostrando a convergência do erro empírico para cada situação (unidades na camada oculta, algoritmo de cálculo do gradiente, taxa de aprendizado). Você deverá deixar claras todas as hipóteses que julgar serem pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1 , Hidden Layers: 25 , Learning Rate: 0.5\n",
      "0.11440000000000002 0.004454211490264016\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 25 , Learning Rate: 1\n",
      "0.12840000000000001 0.031077966471440826\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 25 , Learning Rate: 10\n",
      "0.092 0.008049844718999244\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 50 , Learning Rate: 0.5\n",
      "0.1092 0.008657944328765346\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 50 , Learning Rate: 1\n",
      "0.1212 0.031555665101531294\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 50 , Learning Rate: 10\n",
      "0.092 0.008049844718999244\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 100 , Learning Rate: 0.5\n",
      "0.1654 0.048681002454756414\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 100 , Learning Rate: 1\n",
      "0.10300000000000001 0.018729655629509054\n",
      "\n",
      "Batch size: 1 , Hidden Layers: 100 , Learning Rate: 10\n",
      "0.092 0.008049844718999244\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 25 , Learning Rate: 0.5\n",
      "0.13040000282227995 0.022464194210972083\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 25 , Learning Rate: 1\n",
      "0.1352000028640032 0.016773789501609893\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 25 , Learning Rate: 10\n",
      "0.11520000240206718 0.032387652822728034\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 50 , Learning Rate: 0.5\n",
      "0.21240000461041925 0.041596154686238875\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 50 , Learning Rate: 1\n",
      "0.1446000028848648 0.04216444087581273\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 50 , Learning Rate: 10\n",
      "0.10460000203549862 0.01360294118477044\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 100 , Learning Rate: 0.5\n",
      "0.17560000412166116 0.060165107941400724\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 100 , Learning Rate: 1\n",
      "0.13420000270009041 0.05780795919413798\n",
      "\n",
      "Batch size: 10 , Hidden Layers: 100 , Learning Rate: 10\n",
      "0.09200000168383121 0.008049845005551325\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 25 , Learning Rate: 0.5\n",
      "0.24179999925196172 0.0663216406109379\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 25 , Learning Rate: 1\n",
      "0.18240000072866677 0.07759020660800663\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 25 , Learning Rate: 10\n",
      "0.12399999961256983 0.016673332425493254\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 50 , Learning Rate: 0.5\n",
      "0.3064000003784895 0.05239313044352936\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 50 , Learning Rate: 1\n",
      "0.23799999937415123 0.05130691831492471\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 50 , Learning Rate: 10\n",
      "0.09479999981820583 0.014288457340817988\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 100 , Learning Rate: 0.5\n",
      "0.3564000008255243 0.10787511364351232\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 100 , Learning Rate: 1\n",
      "0.24919999945908783 0.08970484922348332\n",
      "\n",
      "Batch size: 50 , Hidden Layers: 100 , Learning Rate: 10\n",
      "0.100999999307096 0.01017840901717302\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 25 , Learning Rate: 0.5\n",
      "0.8391999959945678 0.01697528778754453\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 25 , Learning Rate: 1\n",
      "0.8457999944686889 0.011391225173294604\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 25 , Learning Rate: 10\n",
      "0.3860000029206276 0.15856860164311987\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 50 , Learning Rate: 0.5\n",
      "0.8770000100135803 0.008294578978832366\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 50 , Learning Rate: 1\n",
      "0.8746000051498413 0.008236496489435637\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 50 , Learning Rate: 10\n",
      "0.17800000160932541 0.03916631179794248\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 100 , Learning Rate: 0.5\n",
      "0.8910000085830688 0.011916373927312934\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 100 , Learning Rate: 1\n",
      "0.8946000099182129 0.0069455016281453705\n",
      "\n",
      "Batch size: 5000 , Hidden Layers: 100 , Learning Rate: 10\n",
      "0.16939999759197236 0.07369830451300013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting a early stopping callback...\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, verbose=0, mode='auto')\n",
    "n_epochs = 100\n",
    "\n",
    "for b_size in [1, 10, 50, len(Y)]:\n",
    "    for n_hl in [25, 50, 100]:\n",
    "        for p_lr in [0.5, 1, 10]:\n",
    "            kmodel = KerasClassifier(build_fn=ML_Model(p_lr, n_hl), epochs=n_epochs, batch_size=b_size, verbose=0,\n",
    "                                     validation_split=0.16)\n",
    "            \n",
    "            kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            print('Batch size:', b_size, ', Hidden Layers:', n_hl, ', Learning Rate:', p_lr)\n",
    "            results = cross_val_score(kmodel, X, Y, cv=kfold, n_jobs=-1)\n",
    "            print(results.mean(), results.std())\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\- Thiago Vieira de Alcantara Silva <br>\n",
    "2017719891"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
